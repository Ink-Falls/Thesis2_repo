{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bccd56c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries for Data Manipulation and System Interaction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Scikit-learn for Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Scikit-learn for Evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95039bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blueprint configured for a single run:\n",
      " -> Dataset: baseline.csv\n",
      " -> Model: LogisticRegression\n",
      " -> Run ID (Random State): 1\n"
     ]
    }
   ],
   "source": [
    "# --- Define the parameters for this single, perfect run ---\n",
    "\n",
    "# 1. Data Parameters\n",
    "DATASET_PATH = os.path.join(\"..\", \"data\", \"processed\", \"baseline.csv\")\n",
    "TARGET_VARIABLE = \"Result\"\n",
    "\n",
    "# 2. Model Parameters\n",
    "MODEL_CHOICE = (\n",
    "    \"LogisticRegression\"  # Options: 'LogisticRegression', 'KNN', 'RandomForest'\n",
    ")\n",
    "RANDOM_STATE = 1  # We use this to ensure our data split and model are reproducible. Corresponds to run_id=1.\n",
    "\n",
    "print(f\"Blueprint configured for a single run:\")\n",
    "print(f\" -> Dataset: {os.path.basename(DATASET_PATH)}\")\n",
    "print(f\" -> Model: {MODEL_CHOICE}\")\n",
    "print(f\" -> Run ID (Random State): {RANDOM_STATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6d02a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Shape of the dataset: (1511, 20)\n",
      "\n",
      "Original target values: ['positive' 'negative']\n",
      "Encoded target values: [1 0]\n",
      "\n",
      "First 5 rows (after target encoding):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Hemoglobin(g/dl)</th>\n",
       "      <th>Neutrophils(%)</th>\n",
       "      <th>Lymphocytes(%)</th>\n",
       "      <th>Monocytes(%)</th>\n",
       "      <th>Eosinophils(%)</th>\n",
       "      <th>RBC</th>\n",
       "      <th>HCT(%)</th>\n",
       "      <th>MCV(fl)</th>\n",
       "      <th>MCH(pg)</th>\n",
       "      <th>MCHC(g/dl)</th>\n",
       "      <th>RDW-CV(%)</th>\n",
       "      <th>Total Platelet Count(/cumm)</th>\n",
       "      <th>MPV(fl)</th>\n",
       "      <th>PDW(%)</th>\n",
       "      <th>PCT(%)</th>\n",
       "      <th>Total WBC count(/cumm)</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>14.8</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>48.00</td>\n",
       "      <td>96.0</td>\n",
       "      <td>29.60</td>\n",
       "      <td>30.8</td>\n",
       "      <td>11.6</td>\n",
       "      <td>112000</td>\n",
       "      <td>10.70</td>\n",
       "      <td>15.40</td>\n",
       "      <td>0.120</td>\n",
       "      <td>5100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>15.0</td>\n",
       "      <td>47</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>49.80</td>\n",
       "      <td>96.1</td>\n",
       "      <td>28.40</td>\n",
       "      <td>29.5</td>\n",
       "      <td>11.8</td>\n",
       "      <td>96000</td>\n",
       "      <td>10.60</td>\n",
       "      <td>15.80</td>\n",
       "      <td>0.121</td>\n",
       "      <td>4500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>16.3</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>50.10</td>\n",
       "      <td>93.5</td>\n",
       "      <td>31.30</td>\n",
       "      <td>32.7</td>\n",
       "      <td>13.5</td>\n",
       "      <td>184000</td>\n",
       "      <td>10.40</td>\n",
       "      <td>16.40</td>\n",
       "      <td>0.130</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>12.3</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>44.00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>30.50</td>\n",
       "      <td>30.5</td>\n",
       "      <td>14.7</td>\n",
       "      <td>167000</td>\n",
       "      <td>8.10</td>\n",
       "      <td>17.10</td>\n",
       "      <td>0.110</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>16.1</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>50.53</td>\n",
       "      <td>91.0</td>\n",
       "      <td>29.12</td>\n",
       "      <td>29.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>155000</td>\n",
       "      <td>10.52</td>\n",
       "      <td>12.34</td>\n",
       "      <td>0.150</td>\n",
       "      <td>4600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Gender  Age  Hemoglobin(g/dl)  Neutrophils(%)  Lymphocytes(%)  \\\n",
       "0      0    Male   21              14.8              48              47   \n",
       "1      1    Male   30              15.0              47              49   \n",
       "2      2    Male   51              16.3              41              48   \n",
       "3      3  Female   26              12.3              46              49   \n",
       "4      4    Male   35              16.1              45              46   \n",
       "\n",
       "   Monocytes(%)  Eosinophils(%)  RBC  HCT(%)  MCV(fl)  MCH(pg)  MCHC(g/dl)  \\\n",
       "0             3               2    5   48.00     96.0    29.60        30.8   \n",
       "1             6               3    5   49.80     96.1    28.40        29.5   \n",
       "2             4               5    5   50.10     93.5    31.30        32.7   \n",
       "3             7               5    5   44.00     90.0    30.50        30.5   \n",
       "4             4               4    5   50.53     91.0    29.12        29.2   \n",
       "\n",
       "   RDW-CV(%)  Total Platelet Count(/cumm)  MPV(fl)  PDW(%)  PCT(%)  \\\n",
       "0       11.6                       112000    10.70   15.40   0.120   \n",
       "1       11.8                        96000    10.60   15.80   0.121   \n",
       "2       13.5                       184000    10.40   16.40   0.130   \n",
       "3       14.7                       167000     8.10   17.10   0.110   \n",
       "4       15.2                       155000    10.52   12.34   0.150   \n",
       "\n",
       "   Total WBC count(/cumm)  Result  \n",
       "0                    5100       1  \n",
       "1                    4500       1  \n",
       "2                    6000       0  \n",
       "3                    5000       0  \n",
       "4                    4600       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable distribution:\n",
      "Result\n",
      "1    0.684977\n",
      "0    0.315023\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the specified dataset\n",
    "try:\n",
    "    df = pd.read_csv(DATASET_PATH)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    print(f\"Shape of the dataset: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Dataset not found at {DATASET_PATH}. Please check the path.\")\n",
    "    # Stop execution if file not found\n",
    "    assert False, \"Execution halted.\"\n",
    "\n",
    "# --- Target Variable Encoding ---\n",
    "# We map the positive class to 1 and the negative class to 0.\n",
    "print(f\"\\nOriginal target values: {df[TARGET_VARIABLE].unique()}\")\n",
    "df[TARGET_VARIABLE] = df[TARGET_VARIABLE].map({\"positive\": 1, \"negative\": 0})\n",
    "print(f\"Encoded target values: {df[TARGET_VARIABLE].unique()}\")\n",
    "\n",
    "# --- Inspection (Post-Encoding) ---\n",
    "print(\"\\nFirst 5 rows (after target encoding):\")\n",
    "display(df.head())\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(df[TARGET_VARIABLE].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98f749b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Features (X) shape: (1511, 19)\n",
      "Initial Target (y) shape: (1511,)\n",
      "Identified Categorical Features: ['Gender']\n",
      "Identified Numerical Features: ['index', 'Age', 'Hemoglobin(g/dl)', 'Neutrophils(%)', 'Lymphocytes(%)', 'Monocytes(%)', 'Eosinophils(%)', 'RBC', 'HCT(%)', 'MCV(fl)', 'MCH(pg)', 'MCHC(g/dl)', 'RDW-CV(%)', 'Total Platelet Count(/cumm)', 'MPV(fl)', 'PDW(%)', 'PCT(%)', 'Total WBC count(/cumm)']\n",
      "\n",
      "--- Preprocessing Complete ---\n",
      "Shape of final processed training data: (1057, 20)\n",
      "Columns: ['index', 'Age', 'Hemoglobin(g/dl)', 'Neutrophils(%)', 'Lymphocytes(%)', 'Monocytes(%)', 'Eosinophils(%)', 'RBC', 'HCT(%)', 'MCV(fl)', 'MCH(pg)', 'MCHC(g/dl)', 'RDW-CV(%)', 'Total Platelet Count(/cumm)', 'MPV(fl)', 'PDW(%)', 'PCT(%)', 'Total WBC count(/cumm)', 'Gender_Female', 'Gender_Male']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1. Separate Features (X) and Target (y)\n",
    "X = df.drop(columns=[TARGET_VARIABLE])\n",
    "y = df[TARGET_VARIABLE]\n",
    "\n",
    "print(f\"Initial Features (X) shape: {X.shape}\")\n",
    "print(f\"Initial Target (y) shape: {y.shape}\")\n",
    "\n",
    "# 2. First Split: Create the Training Set and a Temporary \"Holding\" Set (Test + Validation)\n",
    "# We split 70% for training, leaving 30% in the holding set.\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# 3. Second Split: Split the \"Holding\" Set into Validation and Test Sets\n",
    "# The holding set is 30% of the original data. We split it in half (50/50) to get\n",
    "# two sets that are each 15% of the original data.\n",
    "# test_size=0.5 means 50% of the 30% holding set -> 15% of the total.\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=RANDOM_STATE, stratify=y_temp\n",
    ")\n",
    "\n",
    "# --- Isolate Numerical and Categorical Columns ---\n",
    "categorical_features = [\"Gender\"]  # Add other categorical columns here if any\n",
    "numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "print(f\"Identified Categorical Features: {categorical_features}\")\n",
    "print(f\"Identified Numerical Features: {numerical_features}\")\n",
    "\n",
    "# --- One-Hot Encode Categorical Features ---\n",
    "# We fit the encoder ONLY on the training data.\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "X_train_cat_encoded = ohe.fit_transform(X_train[categorical_features])\n",
    "X_val_cat_encoded = ohe.transform(X_val[categorical_features])\n",
    "X_test_cat_encoded = ohe.transform(X_test[categorical_features])\n",
    "\n",
    "# Create DataFrames with new feature names\n",
    "ohe_feature_names = ohe.get_feature_names_out(categorical_features)\n",
    "X_train_cat_df = pd.DataFrame(\n",
    "    X_train_cat_encoded, index=X_train.index, columns=ohe_feature_names\n",
    ")\n",
    "X_val_cat_df = pd.DataFrame(\n",
    "    X_val_cat_encoded, index=X_val.index, columns=ohe_feature_names\n",
    ")\n",
    "X_test_cat_df = pd.DataFrame(\n",
    "    X_test_cat_encoded, index=X_test.index, columns=ohe_feature_names\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Scale Numerical Features\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train[numerical_features])\n",
    "X_val_num_scaled = scaler.transform(X_val[numerical_features])\n",
    "X_test_num_scaled = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "# Create DataFrames for scaled numerical data\n",
    "X_train_num_df = pd.DataFrame(\n",
    "    X_train_num_scaled, index=X_train.index, columns=numerical_features\n",
    ")\n",
    "X_val_num_df = pd.DataFrame(\n",
    "    X_val_num_scaled, index=X_val.index, columns=numerical_features\n",
    ")\n",
    "X_test_num_df = pd.DataFrame(\n",
    "    X_test_num_scaled, index=X_test.index, columns=numerical_features\n",
    ")\n",
    "\n",
    "\n",
    "# 4. Combine Processed Numerical and Categorical Features\n",
    "X_train_processed = pd.concat([X_train_num_df, X_train_cat_df], axis=1)\n",
    "X_val_processed = pd.concat([X_val_num_df, X_val_cat_df], axis=1)\n",
    "X_test_processed = pd.concat([X_test_num_df, X_test_cat_df], axis=1)\n",
    "\n",
    "print(\"\\n--- Preprocessing Complete ---\")\n",
    "print(f\"Shape of final processed training data: {X_train_processed.shape}\")\n",
    "print(f\"Columns: {X_train_processed.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1139ba2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression model...\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model based on our parameter\n",
    "if MODEL_CHOICE == \"LogisticRegression\":\n",
    "    model = LogisticRegression(random_state=RANDOM_STATE)\n",
    "elif MODEL_CHOICE == \"KNN\":\n",
    "    model = KNeighborsClassifier()  # KNN doesn't have a random_state for initialization\n",
    "elif MODEL_CHOICE == \"RandomForest\":\n",
    "    model = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "else:\n",
    "    raise ValueError(\"Invalid MODEL_CHOICE specified in the parameters.\")\n",
    "\n",
    "print(f\"Training {MODEL_CHOICE} model...\")\n",
    "\n",
    "# Train the model on the scaled training data\n",
    "model.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a320e9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Performance on Validation Set ---\n",
      "Accuracy: 0.7489\n",
      "Precision: 0.7579\n",
      "Recall: 0.9290\n",
      "F1 Score: 0.8348\n",
      "Roc Auc: 0.7111\n",
      "\n",
      "--- Model Performance on Test Set ---\n",
      "Accuracy: 0.7181\n",
      "Precision: 0.7255\n",
      "Recall: 0.9487\n",
      "F1 Score: 0.8222\n",
      "Roc Auc: 0.5872\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(X_data, y_true, set_name):\n",
    "    \"\"\"A helper function to evaluate the model on a given dataset.\"\"\"\n",
    "    y_pred = model.predict(X_data)\n",
    "    y_pred_proba = model.predict_proba(X_data)[:, 1]\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),\n",
    "        \"f1_score\": f1_score(y_true, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_pred_proba),\n",
    "    }\n",
    "\n",
    "    print(f\"\\n--- Model Performance on {set_name} Set ---\")\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        print(f\"{metric_name.replace('_', ' ').title()}: {metric_value:.4f}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Evaluate on the Validation Set\n",
    "val_metrics = evaluate_model(X_val_processed, y_val, \"Validation\")\n",
    "\n",
    "# Evaluate on the Test Set (The final, unbiased evaluation)\n",
    "test_metrics = evaluate_model(X_test_processed, y_test, \"Test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
