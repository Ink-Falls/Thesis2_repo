{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1560537e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries for Data Manipulation and System Interaction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Scikit-learn for Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Scikit-learn for Evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bf5ee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blueprint configured for a single run:\n",
      " -> Dataset: baseline.csv\n",
      " -> Model: LogisticRegression\n",
      " -> Run ID (Random State): 1\n"
     ]
    }
   ],
   "source": [
    "# --- Define the parameters for this single, perfect run ---\n",
    "\n",
    "# 1. Data Parameters\n",
    "DATASET_PATH = os.path.join(\"..\", \"data\", \"processed\", \"baseline.csv\")\n",
    "TARGET_VARIABLE = \"Result\"\n",
    "\n",
    "# 2. Model Parameters\n",
    "MODEL_CHOICE = \"LogisticRegression\"\n",
    "RANDOM_STATE = 1\n",
    "\n",
    "print(f\"Blueprint configured for a single run:\")\n",
    "print(f\" -> Dataset: {os.path.basename(DATASET_PATH)}\")\n",
    "print(f\" -> Model: {MODEL_CHOICE}\")\n",
    "print(f\" -> Run ID (Random State): {RANDOM_STATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76e02977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Shape of the dataset: (1511, 20)\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Hemoglobin(g/dl)</th>\n",
       "      <th>Neutrophils(%)</th>\n",
       "      <th>Lymphocytes(%)</th>\n",
       "      <th>Monocytes(%)</th>\n",
       "      <th>Eosinophils(%)</th>\n",
       "      <th>RBC</th>\n",
       "      <th>HCT(%)</th>\n",
       "      <th>MCV(fl)</th>\n",
       "      <th>MCH(pg)</th>\n",
       "      <th>MCHC(g/dl)</th>\n",
       "      <th>RDW-CV(%)</th>\n",
       "      <th>Total Platelet Count(/cumm)</th>\n",
       "      <th>MPV(fl)</th>\n",
       "      <th>PDW(%)</th>\n",
       "      <th>PCT(%)</th>\n",
       "      <th>Total WBC count(/cumm)</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>14.8</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>48.00</td>\n",
       "      <td>96.0</td>\n",
       "      <td>29.60</td>\n",
       "      <td>30.8</td>\n",
       "      <td>11.6</td>\n",
       "      <td>112000</td>\n",
       "      <td>10.70</td>\n",
       "      <td>15.40</td>\n",
       "      <td>0.120</td>\n",
       "      <td>5100</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>15.0</td>\n",
       "      <td>47</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>49.80</td>\n",
       "      <td>96.1</td>\n",
       "      <td>28.40</td>\n",
       "      <td>29.5</td>\n",
       "      <td>11.8</td>\n",
       "      <td>96000</td>\n",
       "      <td>10.60</td>\n",
       "      <td>15.80</td>\n",
       "      <td>0.121</td>\n",
       "      <td>4500</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>16.3</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>50.10</td>\n",
       "      <td>93.5</td>\n",
       "      <td>31.30</td>\n",
       "      <td>32.7</td>\n",
       "      <td>13.5</td>\n",
       "      <td>184000</td>\n",
       "      <td>10.40</td>\n",
       "      <td>16.40</td>\n",
       "      <td>0.130</td>\n",
       "      <td>6000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>12.3</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>44.00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>30.50</td>\n",
       "      <td>30.5</td>\n",
       "      <td>14.7</td>\n",
       "      <td>167000</td>\n",
       "      <td>8.10</td>\n",
       "      <td>17.10</td>\n",
       "      <td>0.110</td>\n",
       "      <td>5000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>16.1</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>50.53</td>\n",
       "      <td>91.0</td>\n",
       "      <td>29.12</td>\n",
       "      <td>29.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>155000</td>\n",
       "      <td>10.52</td>\n",
       "      <td>12.34</td>\n",
       "      <td>0.150</td>\n",
       "      <td>4600</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Gender  Age  Hemoglobin(g/dl)  Neutrophils(%)  Lymphocytes(%)  \\\n",
       "0      0    Male   21              14.8              48              47   \n",
       "1      1    Male   30              15.0              47              49   \n",
       "2      2    Male   51              16.3              41              48   \n",
       "3      3  Female   26              12.3              46              49   \n",
       "4      4    Male   35              16.1              45              46   \n",
       "\n",
       "   Monocytes(%)  Eosinophils(%)  RBC  HCT(%)  MCV(fl)  MCH(pg)  MCHC(g/dl)  \\\n",
       "0             3               2    5   48.00     96.0    29.60        30.8   \n",
       "1             6               3    5   49.80     96.1    28.40        29.5   \n",
       "2             4               5    5   50.10     93.5    31.30        32.7   \n",
       "3             7               5    5   44.00     90.0    30.50        30.5   \n",
       "4             4               4    5   50.53     91.0    29.12        29.2   \n",
       "\n",
       "   RDW-CV(%)  Total Platelet Count(/cumm)  MPV(fl)  PDW(%)  PCT(%)  \\\n",
       "0       11.6                       112000    10.70   15.40   0.120   \n",
       "1       11.8                        96000    10.60   15.80   0.121   \n",
       "2       13.5                       184000    10.40   16.40   0.130   \n",
       "3       14.7                       167000     8.10   17.10   0.110   \n",
       "4       15.2                       155000    10.52   12.34   0.150   \n",
       "\n",
       "   Total WBC count(/cumm)    Result  \n",
       "0                    5100  positive  \n",
       "1                    4500  positive  \n",
       "2                    6000  negative  \n",
       "3                    5000  negative  \n",
       "4                    4600  negative  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable distribution:\n",
      "Result\n",
      "positive    0.684977\n",
      "negative    0.315023\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the specified dataset\n",
    "try:\n",
    "    df = pd.read_csv(DATASET_PATH)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    print(f\"Shape of the dataset: {df.shape}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(df.head())\n",
    "    print(\"\\nTarget variable distribution:\")\n",
    "    print(df[TARGET_VARIABLE].value_counts(normalize=True))\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Dataset not found at {DATASET_PATH}. Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42a6a3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target classes: ['negative', 'positive']\n",
      "Features (X) shape: (1511, 19)\n",
      "Target (y) shape: (1511,)\n",
      "Categorical columns detected: ['Gender']\n",
      "After encoding, features shape: (1511, 20)\n",
      "\n",
      "--- Data Splitting Complete ---\n",
      "Training set shape:   (1057, 20) (~70%)\n",
      "Validation set shape: (227, 20) (~15%)\n",
      "Test set shape:       (227, 20) (~15%)\n",
      "------------------------------\n",
      "Total rows in Train:   1057 (69.95%)\n",
      "Total rows in Val:     227 (15.02%)\n",
      "Total rows in Test:    227 (15.02%)\n",
      "\n",
      "Features for all three sets scaled successfully (scaler fit on training data only).\n"
     ]
    }
   ],
   "source": [
    "# 1. Separate Features (X) and Target (y)\n",
    "X = df.drop(columns=[TARGET_VARIABLE])\n",
    "y = df[TARGET_VARIABLE]\n",
    "\n",
    "# --- Encode string target labels to numeric ---\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)  # Now y is numeric (e.g., 0/1)\n",
    "print(f\"Target classes: {list(le.classes_)}\")\n",
    "\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Target (y) shape: {y.shape}\")\n",
    "\n",
    "# --- One-hot encode categorical features ---\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Identify categorical columns (object or category dtype)\n",
    "categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "if categorical_cols:\n",
    "    print(f\"Categorical columns detected: {categorical_cols}\")\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "    X_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "    encoded_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "    X_encoded_df = pd.DataFrame(X_encoded, columns=encoded_feature_names, index=X.index)\n",
    "\n",
    "    # Drop original categorical columns and concat encoded columns\n",
    "    X = pd.concat([X.drop(columns=categorical_cols), X_encoded_df], axis=1)\n",
    "    print(f\"After encoding, features shape: {X.shape}\")\n",
    "else:\n",
    "    print(\"No categorical columns detected.\")\n",
    "\n",
    "# 2. First Split: Create the Training Set and a Temporary \"Holding\" Set (Test + Validation)\n",
    "# We split 70% for training, leaving 30% in the holding set.\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# 3. Second Split: Split the \"Holding\" Set into Validation and Test Sets\n",
    "# The holding set is 30% of the original data. We split it in half (50/50) to get\n",
    "# two sets that are each 15% of the original data.\n",
    "# test_size=0.5 means 50% of the 30% holding set -> 15% of the total\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE, stratify=y_temp\n",
    ")\n",
    "\n",
    "# 4. Report the shapes of the final sets to verify the architecture\n",
    "print(\"\\n--- Data Splitting Complete ---\")\n",
    "print(f\"Training set shape:   {X_train.shape} (~70%)\")\n",
    "print(f\"Validation set shape: {X_val.shape} (~15%)\")\n",
    "print(f\"Test set shape:       {X_test.shape} (~15%)\")\n",
    "print(\"-\" * 30)\n",
    "original_rows = len(df)\n",
    "print(f\"Total rows in Train:   {len(X_train)} ({len(X_train)/original_rows:.2%})\")\n",
    "print(f\"Total rows in Val:     {len(X_val)} ({len(X_val)/original_rows:.2%})\")\n",
    "print(f\"Total rows in Test:    {len(X_test)} ({len(X_test)/original_rows:.2%})\")\n",
    "\n",
    "# 5. Scale Features\n",
    "# We fit the scaler ONLY on the training data.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\n",
    "    \"\\nFeatures for all three sets scaled successfully (scaler fit on training data only).\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2861b7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression model...\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model based on our parameter\n",
    "if MODEL_CHOICE == \"LogisticRegression\":\n",
    "    model = LogisticRegression(random_state=RANDOM_STATE)\n",
    "elif MODEL_CHOICE == \"KNN\":\n",
    "    model = KNeighborsClassifier()\n",
    "elif MODEL_CHOICE == \"RandomForest\":\n",
    "    model = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "else:\n",
    "    raise ValueError(\"Invalid MODEL_CHOICE specified in the parameters.\")\n",
    "\n",
    "print(f\"Training {MODEL_CHOICE} model...\")\n",
    "\n",
    "# Train the model on the scaled training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b47e695b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Performance on Validation Set ---\n",
      "Accuracy: 0.7489\n",
      "Precision: 0.7579\n",
      "Recall: 0.9290\n",
      "F1: 0.8348\n",
      "Roc Auc: 0.7107\n",
      "\n",
      "--- Model Performance on Test Set ---\n",
      "Accuracy: 0.7181\n",
      "Precision: 0.7255\n",
      "Recall: 0.9487\n",
      "F1: 0.8222\n",
      "Roc Auc: 0.5872\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(X_data, y_true, set_name):\n",
    "    \"\"\"A helper function to evaluate the model on a given dataset.\"\"\"\n",
    "    y_pred = model.predict(X_data)\n",
    "    y_pred_proba = model.predict_proba(X_data)[:, 1]\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_pred_proba),\n",
    "    }\n",
    "\n",
    "    print(f\"\\n--- Model Performance on {set_name} Set ---\")\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        print(f\"{metric_name.replace('_', ' ').title()}: {metric_value:.4f}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Evaluate on the Validation Set\n",
    "val_metrics = evaluate_model(X_val_scaled, y_val, \"Validation\")\n",
    "\n",
    "# Evaluate on the Test Set (The final, unbiased evaluation)\n",
    "test_metrics = evaluate_model(X_test_scaled, y_test, \"Test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
